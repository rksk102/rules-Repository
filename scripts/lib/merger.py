#!/usr/bin/env python3
import os
import yaml
import glob
import sys
import shutil
import time

# =========================
# é…ç½®åŒºåŸŸ
# =========================
CONFIG_FILE = "merge-config.yaml"
SOURCE_DIR = "rulesets"
DIST_DIR = "merged-rules"

# ç»Ÿè®¡æ•°æ®å®¹å™¨
STATS = {
    "mirrored": 0,
    "skipped": 0,
    "merged_tasks": 0,
    "total_rules": 0,
    "errors": []
}

# =========================
# GitHub Actions è¾…åŠ©å‡½æ•°
# =========================
def gh_group_start(title):
    print(f"::group::ðŸ”¹ {title}")
    sys.stdout.flush()

def gh_group_end():
    print("::endgroup::")
    sys.stdout.flush()

def gh_error(message, file=None):
    if file:
        print(f"::error file={file}::{message}")
    else:
        print(f"::error::{message}")
    STATS["errors"].append(message)

def gh_warning(message):
    print(f"::warning::{message}")

def print_step(msg):
    print(f"\033[1;34m[INFO]\033[0m {msg}")

def print_success(msg):
    print(f"\033[1;32m[OK]\033[0m   {msg}")

# =========================
# æ ¸å¿ƒé€»è¾‘
# =========================

def generate_summary():
    """ç”Ÿæˆ GitHub Step Summary æŠ¥å‘Š"""
    summary_file = os.getenv('GITHUB_STEP_SUMMARY')
    if not summary_file:
        return

    with open(summary_file, 'a', encoding='utf-8') as f:
        f.write("## ðŸš€ Rule Merge Execution Report\n\n")
        
        # çŠ¶æ€æ¦‚è§ˆ
        if STATS["errors"]:
            f.write("### âŒ Failure Detected\n")
            f.write("> Some errors occurred during the process.\n\n")
        else:
            f.write("### âœ… Merge Successful\n")
            f.write("> All rules processed and merged cleanly.\n\n")
        
        # ç»Ÿè®¡è¡¨æ ¼
        f.write("| Metric | Count | Description |\n")
        f.write("| :--- | :---: | :--- |\n")
        f.write(f"| ðŸ“„ **Mirrored Files** | `{STATS['mirrored']}` | Raw files copied without modification |\n")
        f.write(f"| â­ï¸ **Skipped Files** | `{STATS['skipped']}` | Files consumed by input tasks |\n")
        f.write(f"| ðŸ”„ **Merged Tasks** | `{STATS['merged_tasks']}` | Custom rule sets generated |\n")
        f.write(f"| ðŸ“Š **Total Rules** | `{STATS['total_rules']}` | Specific lines valid across all outputs |\n")
        f.write("\n")

        # é”™è¯¯è¯¦æƒ…
        if STATS["errors"]:
            f.write("### âš ï¸ Error Log\n")
            for err in STATS["errors"]:
                f.write(f"- ðŸ”´ {err}\n")

def clean_dist_dir():
    gh_group_start("Cleaning Output Directory")
    if not os.path.exists(DIST_DIR):
        os.makedirs(DIST_DIR)
        print_step(f"Created directory: {DIST_DIR}")
    else:
        print_step(f"Cleaning contents of: {DIST_DIR} ...")
        try:
            for item in os.listdir(DIST_DIR):
                item_path = os.path.join(DIST_DIR, item)
                if os.path.isfile(item_path) or os.path.islink(item_path):
                    os.unlink(item_path)
                elif os.path.isdir(item_path):
                    shutil.rmtree(item_path)
            print_success("Directory emptied successfully.")
        except Exception as e:
            gh_error(f"Failed to clean directory: {e}")
            sys.exit(1)
    gh_group_end()

def load_config(path):
    if not os.path.exists(path):
        gh_error(f"Config file not found", file=path)
        sys.exit(1)
    
    try:
        with open(path, 'r', encoding='utf-8') as f:
            # é¢„è¯»å–æ£€æŸ¥ YAML è¯­æ³•
            return yaml.safe_load(f)
    except yaml.YAMLError as exc:
        gh_error(f"YAML Syntax Error: {exc}", file=path)
        sys.exit(1)

def get_file_content(filepath):
    lines = set()
    try:
        with open(filepath, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('//'):
                    continue
                lines.add(line)
    except Exception as e:
        gh_warning(f"Cannot read {filepath}: {e}")
    return lines

def write_txt(rel_path, rules, description=""):
    full_path = os.path.join(DIST_DIR, rel_path)
    os.makedirs(os.path.dirname(full_path), exist_ok=True)
    
    try:
        with open(full_path, 'w', encoding='utf-8') as f:
            if description: f.write(f"# {description}\n")
            f.write(f"# Total Rules: {len(rules)}\n")
            f.write(f"# Generated by Rule-Merge-System at {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            for rule in sorted(list(rules)):
                f.write(f"{rule}\n")
        
        print_success(f"Generated: {rel_path} ({len(rules)} lines)")
        STATS["total_rules"] += len(rules)
    except Exception as e:
        gh_error(f"Failed to write file {full_path}: {e}")

def collect_used_files(config):
    used = set()
    if not config or 'merges' not in config: return used
    for task in config['merges']:
        for idx, input_pattern in enumerate(task.get('inputs', [])):
            full_pattern = os.path.join(SOURCE_DIR, input_pattern)
            found = glob.glob(full_pattern, recursive=True)
            if not found:
                # è¿™æ˜¯ä¸€ä¸ªå°è­¦å‘Šï¼Œæç¤ºé€šé…ç¬¦å†™é”™äº†æˆ–è€…æ²¡ä¸‹è½½åˆ°æ–‡ä»¶
                print(f"\033[33m[WARN]\033[0m Input pattern matched nothing: {input_pattern}")
            for f in found:
                if os.path.isfile(f): used.add(os.path.abspath(f))
    return used

def mirror_raw_files(exclude_files):
    gh_group_start("Phase 1: Mirroring Raw Files")
    print_step(f"Scanning {SOURCE_DIR} for files to mirror...")
    
    for root, dirs, files in os.walk(SOURCE_DIR):
        for file in files:
            if not file.endswith(('.txt', '.list', '.yaml', '.conf')):
                continue
            
            src_path = os.path.join(root, file)
            if os.path.abspath(src_path) in exclude_files:
                STATS["skipped"] += 1
                continue

            rel_path = os.path.relpath(src_path, SOURCE_DIR)
            dest_path = os.path.join(DIST_DIR, rel_path)
            
            os.makedirs(os.path.dirname(dest_path), exist_ok=True)
            shutil.copy2(src_path, dest_path)
            STATS["mirrored"] += 1
            # ä»…åœ¨éžå¸¸è¯¦ç»†æ¨¡å¼ä¸‹æ‰“å°æ¯ä¸ªæ–‡ä»¶ï¼Œé¿å…æ—¥å¿—åˆ·å±
            # print(f"  -> Mirrored: {rel_path}")

    print_success(f"Mirrored {STATS['mirrored']} files. Skipped {STATS['skipped']} (merged).")
    gh_group_end()

def process_merges(config):
    gh_group_start("Phase 2: Processing Merge Tasks")
    
    if not config or 'merges' not in config:
        print("No merge tasks defined.")
        gh_group_end()
        return

    tasks = config['merges']
    print_step(f"Found {len(tasks)} merge definitions.")

    for task in tasks:
        name = task.get('name')
        inputs = task.get('inputs', [])
        desc = task.get('description', "")
        
        if not name or not inputs:
            gh_warning(f"Skipping invalid task config: {task}")
            continue
            
        print(f"ðŸ”¹ Processing: {name}")
        merged = set()
        file_count = 0
        
        for patt in inputs:
            full_patt = os.path.join(SOURCE_DIR, patt)
            for fp in glob.glob(full_patt, recursive=True):
                if os.path.isfile(fp):
                    content = get_file_content(fp)
                    merged.update(content)
                    file_count += 1
        
        if file_count == 0:
            gh_warning(f"Zero input files found for task: {name}")
        else:
            write_txt(name, merged, desc)
            STATS["merged_tasks"] += 1

    gh_group_end()

def main():
    print("::notice::Starting Rule Merge System...")
    
    clean_dist_dir()

    gh_group_start("Loading Configuration")
    config = load_config(CONFIG_FILE)
    used_files = collect_used_files(config)
    print_success(f"Configuration loaded. {len(used_files)} files targeted for merging.")
    gh_group_end()

    mirror_raw_files(used_files)
    process_merges(config)

    generate_summary()
    print("::notice::Workflow Completed Successfully.")

if __name__ == "__main__":
    main()
