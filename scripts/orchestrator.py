#!/usr/bin/env python3
import json
import subprocess
import sys
import time
import os

# =================é…ç½®=================
PLAN_FILE = "workflow_plan.json"
# =====================================

def log(msg, level="info"):
    icons = {"info": "â„¹ï¸", "success": "âœ…", "error": "âŒ", "wait": "â³"}
    print(f"{icons.get(level, '')} {msg}")
    sys.stdout.flush()

def run_command(cmd):
    """æ‰§è¡Œ Shell å‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)
        return result.stdout.strip()
    except subprocess.CalledProcessError as e:
        log(f"Command failed: {cmd}\nError: {e.stderr}", "error")
        return None

def trigger_workflow(workflow_file):
    """è§¦å‘å·¥ä½œæµ"""
    log(f"Triggering {workflow_file}...", "wait")
    # ä½¿ç”¨ gh workflow run è§¦å‘
    if run_command(f"gh workflow run {workflow_file} --ref {os.getenv('GITHUB_REF_NAME', 'main')}") is not None:
        return True
    return False

def get_latest_run_id(workflow_file):
    """è·å–æŸå·¥ä½œæµæ­£åœ¨è¿è¡Œçš„æœ€æ–° Run ID"""
    # ç­‰å¾…å‡ ç§’è®© GitHub API åˆ·æ–°
    time.sleep(5)
    # è·å–æœ€æ–°çš„ä¸€ä¸ª run (æ— è®ºçŠ¶æ€)
    output = run_command(f"gh run list --workflow {workflow_file} --limit 1 --json databaseId,status --jq '.[0]'")
    if output:
        data = json.loads(output)
        return data['databaseId']
    return None

def watch_workflow(run_id, timeout_mins):
    """é˜»å¡ç­‰å¾…å·¥ä½œæµå®Œæˆ"""
    log(f"Watching run ID: {run_id} (Timeout: {timeout_mins}m)...", "wait")
    
    # ä½¿ç”¨ gh run watch è‡ªåŠ¨è½®è¯¢ç›´åˆ°ç»“æŸ
    # --exit-status ä¼šè®©å‘½ä»¤åœ¨å·¥ä½œæµå¤±è´¥æ—¶è¿”å›é 0 å€¼
    cmd = f"gh run watch {run_id} --exit-status"
    
    try:
        # è¿™é‡Œä¸ä½¿ç”¨ run_command å› ä¸ºæˆ‘ä»¬éœ€è¦å®æ—¶çœ‹åˆ° watch çš„è¾“å‡ºï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰ï¼Œæˆ–è€…å•çº¯é˜»å¡
        # ä½† gh run watch é»˜è®¤å¾ˆå®‰é™ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¤„ç†è¶…æ—¶
        subprocess.run(cmd, shell=True, check=True, timeout=timeout_mins * 60)
        return True
    except subprocess.TimeoutExpired:
        log(f"Workflow timed out after {timeout_mins} minutes!", "error")
        return False
    except subprocess.CalledProcessError:
        log("Workflow failed!", "error")
        return False

def main():
    if not os.path.exists(PLAN_FILE):
        log(f"Plan file {PLAN_FILE} not found!", "error")
        sys.exit(1)

    with open(PLAN_FILE, 'r', encoding='utf-8') as f:
        plan = json.load(f)

    print(f"::group::ğŸš€ Starting Orchestrator for {len(plan)} workflows")
    
    for step in plan:
        name = step['name']
        file = step['file']
        timeout = step.get('timeout_minutes', 20)

        print(f"\n----------------------------------------")
        log(f"Step: {name} ({file})", "info")
        
        # 1. è®°å½•å½“å‰æœ€æ–°çš„ ID (é˜²æ­¢æ•æ‰åˆ°æ—§çš„)
        # old_id = get_latest_run_id(file) 
        # å®é™…ä¸Š gh run watch é€»è¾‘æ¯”è¾ƒæ™ºèƒ½ï¼Œæˆ‘ä»¬è¿™é‡Œé‡‡ç”¨ç›´æ¥ Trigger åè·å–æœ€æ–°çš„ç­–ç•¥
        
        # 2. è§¦å‘
        if not trigger_workflow(file):
            log(f"Failed to trigger {name}", "error")
            sys.exit(1)

        # 3. è·å–åˆšåˆšè§¦å‘çš„ ID
        # ç¨å¾®ç­‰å¾… GitHub ç”Ÿæˆ ID
        time.sleep(3)
        current_id = get_latest_run_id(file)
        
        if not current_id:
            log(f"Could not find run ID for {file}", "error")
            sys.exit(1)

        # 4. ç›‘æ§ç›´åˆ°ç»“æŸ
        if watch_workflow(current_id, timeout):
            log(f"Step {name} finished successfully!", "success")
        else:
            log(f"Step {name} failed or timed out. Stopping orchestrator.", "error")
            sys.exit(1) # åªè¦æœ‰ä¸€æ­¥å¤±è´¥ï¼Œæ•´ä¸ªé“¾æ¡åœæ­¢

    print("----------------------------------------")
    print("::endgroup::")
    log("ğŸ‰ All workflows in the plan completed successfully!", "success")

if __name__ == "__main__":
    main()
