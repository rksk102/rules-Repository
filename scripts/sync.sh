#!/usr/bin/env bash
set -uo pipefail

# ================= CONFIGURATION =================
STRICT_MODE="${STRICT_MODE:-false}"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROCESSOR="${SCRIPT_DIR}/lib/processor.py"
SOURCE_DIR="rulesets"
TEMP_DIR="${RUNNER_TEMP:-/tmp}/sync-engine"
mkdir -p "$TEMP_DIR"

# Icons
ICON_OK="âœ…"
ICON_FAIL="âŒ"
ICON_WARN="âš ï¸"
ICON_WORK="âš™ï¸"

# ================= FUNCTIONS =================

cleanup() {
  rm -rf "$TEMP_DIR"
}
trap cleanup EXIT

# ã€æ ¸å¿ƒä¿®æ­£ã€‘ç²¾å‡†æå–æ¥æºä½œè€… (Owner)
get_owner() {
  local url="$1"
  # æå–åŸŸå (ç¬¬3æ®µ)
  local domain=$(echo "$url" | awk -F/ '{print $3}')

  if [[ "$domain" == *"github"* ]]; then
    # åŒ¹é… github.com å’Œ raw.githubusercontent.com
    # æ ¼å¼é€šå¸¸æ˜¯: https://site/USER/REPO/...
    # ç¬¬4æ®µå³ä¸ºç”¨æˆ·å
    echo "$url" | awk -F/ '{print $4}'
    
  elif [[ "$domain" == "cdn.jsdelivr.net" ]]; then
    # æ ¼å¼: https://cdn.jsdelivr.net/gh/USER/REPO...
    local type_seg=$(echo "$url" | awk -F/ '{print $4}')
    if [ "$type_seg" == "gh" ]; then
        echo "$url" | awk -F/ '{print $5}'
    else
        echo "jsdelivr"
    fi
  else
    # æ™®é€šåŸŸåç›´æ¥ä½œä¸ºä½œè€…å (å¦‚ dl.google.com)
    echo "$domain"
  fi
}

normalize_args() {
  local input="${1,,}"
  case "$input" in
    *reject*|*block*|*deny*|*ads*|*adblock*) echo "block" ;;
    *direct*|*bypass*|*no-proxy*)           echo "direct" ;;
    *proxy*|*gfw*)                          echo "proxy" ;;
    *)                                      echo "${input:-proxy}" ;;
  esac
}

normalize_type() {
  local input="${1,,}"
  case "$input" in
    *ip*|*cidr*) echo "ipcidr" ;;
    *)           echo "domain" ;;
  esac
}

# ã€è·¯å¾„ç”Ÿæˆã€‘ç¡®ä¿å±‚çº§: ç­–ç•¥/ç±»å‹/ä½œè€…/æ–‡ä»¶.txt
map_filename() {
  local policy="$1"
  local type="$2"
  local owner="$3"
  local url="$4"
  
  local filename=$(basename "$url")
  # å¼ºåˆ¶å»é™¤æ‰€æœ‰åç¼€ï¼Œç»Ÿä¸€åŠ  .txt
  local base="${filename%.*}"
  
  # æœ€ç»ˆè·¯å¾„ç»“æ„
  echo "${policy}/${type}/${owner}/${base}.txt"
}

# ================= MAIN EXECUTION =================

echo "::group::ğŸ”§ Initialization"
if [ ! -f "$PROCESSOR" ]; then
  echo "::error::Helper script processor.py not found!"
  exit 1
fi

if [ ! -f sources.urls ]; then
  echo "::warning::sources.urls file missing."
  exit 0
fi

# é¢„å¤„ç†æºåˆ—è¡¨
awk 'NR==1{sub(/^\xEF\xBB\xBF/,"")} {print}' sources.urls \
  | sed 's/\r$//' | sed -E 's/[[:space:]]+#.*$//' \
  | grep -v "^$" > "${TEMP_DIR}/clean_sources.list"
echo "Loaded $(wc -l < "${TEMP_DIR}/clean_sources.list") sources."
echo "::endgroup::"

# --- 1. ç”Ÿæˆä»»åŠ¡åˆ—è¡¨ ---
TASKS_FILE="${TEMP_DIR}/tasks.tsv"
: > "$TASKS_FILE"

current_pol="proxy"
current_typ="domain"

while read -r line; do
  if [[ "$line" =~ ^\[policy:(.+)\]$ ]]; then current_pol="$(normalize_args "${BASH_REMATCH[1]}")"; continue; fi
  if [[ "$line" =~ ^\[type:(.+)\]$ ]]; then current_typ="$(normalize_type "${BASH_REMATCH[1]}")"; continue; fi
  
  if [[ "$line" =~ https?:// ]]; then
    url=$(echo "$line" | grep -oE 'https?://[^ ]+')
    echo -e "${current_pol}\t${current_typ}\t${url}" >> "$TASKS_FILE"
  fi
done < "${TEMP_DIR}/clean_sources.list"

# --- 2. å­¤å„¿æ–‡ä»¶æ¸…ç† (Orphan Cleaning) ---
echo "::group::ğŸ§¹ Cleaning Orphan Files"
EXPECTED_FILES="${TEMP_DIR}/expected.txt"
: > "$EXPECTED_FILES"

# è®¡ç®—é¢„æœŸå­˜åœ¨çš„æ–‡ä»¶è·¯å¾„
while IFS=$'\t' read -r p t u; do
  owner=$(get_owner "$u")
  rel_path=$(map_filename "$p" "$t" "$owner" "$u")
  echo "${SOURCE_DIR}/${rel_path}" >> "$EXPECTED_FILES"
done < "$TASKS_FILE"

if [ -d "$SOURCE_DIR" ]; then
  # æ‰¾å‡ºå®é™…å­˜åœ¨çš„æ–‡ä»¶
  find "$SOURCE_DIR" -type f | sort > "${TEMP_DIR}/actual.txt"
  sort "$EXPECTED_FILES" -o "$EXPECTED_FILES"
  
  # å¯¹æ¯”åˆ é™¤
  comm -23 "${TEMP_DIR}/actual.txt" "$EXPECTED_FILES" | while read -r f; do
    echo "Deleting orphan: $f"
    rm -f "$f"
  done
  
  # æ¸…ç†ç©ºç›®å½•
  find "$SOURCE_DIR" -type d -empty -delete 2>/dev/null || true
fi
echo "::endgroup::"

# --- 3. ä¸‹è½½ä¸å¤„ç†å¾ªç¯ ---
FAIL_COUNT=0

while IFS=$'\t' read -r policy type url; do
  fn=$(basename "$url")
  owner=$(get_owner "$url") # æå–ä½œè€…å
  
  # å½’ä¸€åŒ–å‚æ•°
  pol=$(normalize_args "$policy")
  typ=$(normalize_type "$type")
  
  rel_path=$(map_filename "$pol" "$typ" "$owner" "$url")
  abs_path="${SOURCE_DIR}/${rel_path}"
  
  echo "::group::${ICON_WORK} [${pol}/${typ}] ${owner}/${fn}"
  echo "Source: $url"
  echo "Target: rulesets/$rel_path"
  
  mkdir -p "$(dirname "$abs_path")"
  
  # ä¸‹è½½
  DL_FILE="${abs_path}.tmp"
  HTTP_CODE=$(curl -sL --connect-timeout 15 --retry 2 -w "%{http_code}" -o "$DL_FILE" "$url")
  
  if [ "$HTTP_CODE" -lt 200 ] || [ "$HTTP_CODE" -ge 300 ]; then
    echo "::error::Download failed ($HTTP_CODE)"
    echo "ERROR_DL: $url"
    rm -f "$DL_FILE"
    FAIL_COUNT=$((FAIL_COUNT+1))
    echo "::endgroup::"
    [ "$STRICT_MODE" = "true" ] && exit 1
    continue
  fi
  
  # æ¸…æ´— (è°ƒç”¨ processor.py)
  PY_MODE="domain"
  [ "$typ" == "ipcidr" ] && PY_MODE="ipcidr"
  
  if python3 "$PROCESSOR" "$PY_MODE" < "$DL_FILE" > "$abs_path"; then
    LINES=$(wc -l < "$abs_path")
    echo "SUCCESS: Saved $LINES lines."
    rm -f "$DL_FILE"
  else
    echo "::error::Sanitize failed!"
    echo "ERROR_PARSE: $url"
    rm -f "$DL_FILE" "$abs_path"
    FAIL_COUNT=$((FAIL_COUNT+1))
    echo "::endgroup::"
    [ "$STRICT_MODE" = "true" ] && exit 1
    continue
  fi
  
  echo "::endgroup::"

done < "$TASKS_FILE"

# --- 4. ç»“æœæ±‡æŠ¥ ---
if [ "$FAIL_COUNT" -gt 0 ]; then
  echo "::error::Completed with $FAIL_COUNT errors."
  exit 1
fi

# --- 5. Git æäº¤ ---
echo "::group::ğŸ’¾ Git Commit"
git config user.name 'GitHub Actions Bot'
git config user.email 'actions@github.com'
git add -A
if git diff-index --quiet HEAD; then
  echo "No changes."
else
  echo "Pushing changes..."
  git commit -m "chore(sync): Rules update $(date +'%Y-%m-%d')"
  git push
fi
echo "::endgroup::"
