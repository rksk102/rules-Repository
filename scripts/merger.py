#!/usr/bin/env python3
import os
import sys
import yaml
import ipaddress
import time
from pathlib import Path
from rich.console import Console
from rich.table import Table
from rich.panel import Panel
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn
from rich.traceback import install

install(show_locals=True)
console = Console()

# =========================
# é…ç½®åŒºåŸŸ
# =========================
CONFIG_FILE = "merge-config.yaml"
SOURCE_DIR = "rulesets"
OUTPUT_DIR = "merged-rules"

STATS = {
    "success": 0,
    "skipped": 0,
    "failed": 0,
    "total_rules": 0
}
ERROR_LOGS = []
SUMMARY_ROWS = []

# æ ¸å¿ƒä¿®æ”¹ï¼šç”¨äºŽè®°å½•å“ªäº›æ–‡ä»¶å·²ç»è¢«é…ç½®ä»»åŠ¡ä½¿ç”¨äº†
USED_SOURCE_FILES = set()

# =========================
# åŠŸèƒ½å‡½æ•°
# =========================

def normalize_path(p):
    """æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦ï¼Œä¾¿äºŽæ¯”å¯¹"""
    return str(Path(p).as_posix())

def detect_mode(type_str, filename):
    check_str = (str(type_str) + str(filename)).lower()
    if 'ip' in check_str or 'cidr' in check_str:
        return 'IP-CIDR'
    return 'DOMAIN'

def flatten_ip_cidr(cidr_set):
    """IPv4/IPv6 åˆ†ç¦»èšåˆç®—æ³•"""
    ipv4_nets = []
    ipv6_nets = []
    for c in cidr_set:
        c = c.strip()
        if not c: continue
        try:
            net = ipaddress.ip_network(c, strict=False)
            if net.version == 4: ipv4_nets.append(net)
            else: ipv6_nets.append(net)
        except ValueError as e:
            raise ValueError(f"Invalid CIDR '{c}': {e}")
    
    v4_res = [str(n) for n in ipaddress.collapse_addresses(ipv4_nets)]
    v6_res = [str(n) for n in ipaddress.collapse_addresses(ipv6_nets)]
    return v4_res + v6_res

def process_task_logic(strategy, rule_type, owner, filename, inputs, desc):
    """é€šç”¨çš„ä»»åŠ¡å¤„ç†æ ¸å¿ƒé€»è¾‘"""
    
    # æž„å»ºè¾“å‡ºè·¯å¾„
    relative_dir = os.path.join(strategy, rule_type, owner)
    full_output_dir = os.path.join(OUTPUT_DIR, relative_dir)
    full_output_file = os.path.join(full_output_dir, filename)

    combined_rules = set()
    files_read_count = 0

    for rel_input in inputs:
        # è®°å½•æ–‡ä»¶å·²è¢«ä½¿ç”¨ (æ ‡å‡†åŒ–è·¯å¾„)
        full_src_path = os.path.join(SOURCE_DIR, rel_input)
        rel_src_norm = normalize_path(rel_input)
        USED_SOURCE_FILES.add(rel_src_norm)

        if not os.path.exists(full_src_path):
            raise FileNotFoundError(f"Source file not found: {full_src_path}")
        
        with open(full_src_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith('#') or line.startswith('//'): continue
                if '#' in line: line = line.split('#')[0].strip()
                combined_rules.add(line)
            files_read_count += 1

    if files_read_count == 0 and inputs:
        return None

    # å¤„ç†æ•°æ®
    mode = detect_mode(rule_type, filename)
    raw_count = len(combined_rules)
    
    if mode == 'IP-CIDR':
        final_list = flatten_ip_cidr(combined_rules)
    else:
        final_list = sorted(list(combined_rules))
    
    opt_count = len(final_list)

    # å†™å…¥æ–‡ä»¶
    os.makedirs(full_output_dir, exist_ok=True)
    with open(full_output_file, 'w', encoding='utf-8') as f:
        f.write(f"# ----------------------------------------\n")
        f.write(f"# Strategy: {strategy}\n")
        f.write(f"# Type:     {rule_type}\n")
        f.write(f"# Owner:    {owner}\n")
        f.write(f"# Date:     {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"# Mode:     {mode}\n")
        f.write(f"# Count:    {opt_count} (Raw: {raw_count})\n")
        f.write(f"# Desc:     {desc}\n")
        f.write(f"# ----------------------------------------\n")
        f.write("\n".join(final_list))
        f.write("\n")

    return {
        "file": filename,
        "path": f"{strategy}/{rule_type}/{owner}",
        "mode": mode,
        "src_count": files_read_count,
        "raw": raw_count,
        "opt": opt_count
    }

def auto_discover_files():
    """æ‰«æ rulesets æ–‡ä»¶å¤¹ï¼Œå‘çŽ°æœªä½¿ç”¨çš„æ–‡ä»¶"""
    discovered_tasks = []
    
    # éåŽ† rulesets ç›®å½•
    for root, dirs, files in os.walk(SOURCE_DIR):
        for file in files:
            if file.startswith('.') or not file.endswith('.txt'):
                continue

            # èŽ·å–ç›¸å¯¹äºŽ rulesets çš„è·¯å¾„ï¼Œä¾‹å¦‚ inputs/ads/list.txt
            abs_path = os.path.join(root, file)
            rel_path = os.path.relpath(abs_path, SOURCE_DIR)
            rel_path_norm = normalize_path(rel_path)

            # æ ¸å¿ƒåˆ¤æ–­ï¼šå¦‚æžœè¿™ä¸ªæ–‡ä»¶å·²ç»åœ¨ YAML ä»»åŠ¡é‡Œç”¨è¿‡äº†ï¼Œè·³è¿‡ï¼
            if rel_path_norm in USED_SOURCE_FILES:
                continue

            # è‡ªåŠ¨æŽ¨æ–­ Strategy/Type/Owner
            # å‡è®¾ç›®å½•ç»“æž„æ˜¯ rulesets/Strategy/Type/Owner/File.txt
            parts = Path(rel_path_norm).parent.parts
            
            # é»˜è®¤å€¼
            d_strat = "Auto"
            d_type = "General"
            d_owner = "Unknown"

            if len(parts) >= 1: d_strat = parts[0]
            if len(parts) >= 2: d_type = parts[1]
            if len(parts) >= 3: d_owner = parts[2]
            # å¦‚æžœè¿˜æœ‰æ›´æ·±å±‚çº§ï¼Œå¯ä»¥æ‹¼æŽ¥åˆ° Owner æˆ–è€…å¿½ç•¥

            discovered_tasks.append({
                "strategy": d_strat,
                "type": d_type,
                "owner": d_owner,
                "filename": file,
                "inputs": [rel_path_norm],
                "description": f"Auto-detected from {rel_path_norm}"
            })
            
    return discovered_tasks

# =========================
# ä¸»ç¨‹åº
# =========================

def main():
    console.rule("[bold blue]ðŸš€ Hybrid Merger (Config + Auto-Scan)[/bold blue]")

    # 1. è¯»å–é…ç½®çš„ä»»åŠ¡
    config_tasks = []
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, 'r') as f:
                data = yaml.safe_load(f) or {}
                config_tasks = data.get('merges', [])
        except Exception as e:
            console.print(f"[red]Config Error:[/red] {e}")
            sys.exit(1)

    # 2. ç»Ÿä¸€æ‰§è¡Œæµç¨‹
    with Progress(
        SpinnerColumn(),
        TextColumn("[bold blue]{task.description}"),
        BarColumn(),
        TaskProgressColumn(),
        console=console
    ) as progress:
        
        # A. æ‰§è¡Œé…ç½®ä»»åŠ¡ (ä¼˜å…ˆ)
        task_main = progress.add_task("[cyan]Running Config Tasks[/cyan]", total=len(config_tasks))
        for t in config_tasks:
            try:
                fname = t.get('filename', 'Unknown')
                progress.update(task_main, description=f"Config Task: {fname}")
                
                # ç®€å•æ ¡éªŒ
                if 'inputs' not in t: raise ValueError("Missing inputs")
                
                res = process_task_logic(
                    t.get('strategy', 'Default'), t.get('type', 'General'),
                    t.get('owner', 'Unknown'), fname, t['inputs'],
                    t.get('description', 'Configured Merge')
                )
                if res:
                    STATS['success'] += 1
                    STATS['total_rules'] += res['opt']
                    SUMMARY_ROWS.append(res)
                else:
                    STATS['skipped'] += 1
            except Exception as e:
                STATS['failed'] += 1
                ERROR_LOGS.append(f"Config Task '{fname}': {str(e)}")
            progress.advance(task_main)

        # B. è‡ªåŠ¨å‘çŽ°å¹¶æ‰§è¡Œ (è¡¥æ¼)
        # å¿…é¡»åœ¨ä¸Šé¢çš„å¾ªçŽ¯é€šè¿‡ USED_SOURCE_FILES è®°å½•å®Œå·²è¢«å ç”¨çš„æ–‡ä»¶åŽï¼Œå†æ‰«æ
        auto_tasks = auto_discover_files()
        
        if auto_tasks:
            task_auto = progress.add_task("[magenta]Running Auto-Discovery[/magenta]", total=len(auto_tasks))
            for t in auto_tasks:
                try:
                    progress.update(task_auto, description=f"Auto Task: {t['filename']}")
                    res = process_task_logic(
                        t['strategy'], t['type'], t['owner'], 
                        t['filename'], t['inputs'], t['description']
                    )
                    if res:
                        STATS['success'] += 1
                        STATS['total_rules'] += res['opt']
                        res['file'] = f"(Auto) {res['file']}" # æ ‡è®°ä¸€ä¸‹
                        SUMMARY_ROWS.append(res)
                except Exception as e:
                    STATS['failed'] += 1
                    ERROR_LOGS.append(f"Auto Task '{t['filename']}': {str(e)}")
                progress.advance(task_auto)

    # 3. æŠ¥å‘Šä¸Žç»“æŸ
    table = Table(title="Execution Summary", header_style="bold magenta")
    table.add_column("File", style="cyan")
    table.add_column("Output Path", style="dim")
    table.add_column("Mode")
    table.add_column("Rules", justify="right", style="green")

    for r in SUMMARY_ROWS:
        table.add_row(r['file'], r['path'], r['mode'], str(r['opt']))
    
    console.print("\n")
    console.print(table)

    if os.getenv('GITHUB_STEP_SUMMARY'):
        with open(os.getenv('GITHUB_STEP_SUMMARY'), 'a') as f:
            f.write(f"### ðŸš€ Rule Report: {STATS['success']} OK, {STATS['failed']} Failed\n\n")
            if ERROR_LOGS:
                f.write("```diff\n" + "\n".join([f"- {e}" for e in ERROR_LOGS]) + "\n```\n")
            f.write("| File | Output Path | Rules |\n|---|---|---|\n")
            for r in SUMMARY_ROWS:
                f.write(f"| `{r['file']}` | `{r['path']}` | **{r['opt']}** |\n")

    if STATS["failed"] > 0:
        sys.exit(1)

if __name__ == "__main__":
    main()
